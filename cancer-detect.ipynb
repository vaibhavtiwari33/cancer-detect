{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE228_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavtiwari33/cancer-detect/blob/main/cancer-detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX8JhWl3iwHG"
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "# Import Libraries here\n",
        "import os\n",
        "import json \n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wUC1Mtc4_bJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "import pandas as pd"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM8DlN_WG5Xv",
        "outputId": "dae2c9f7-9167-4598-f529-9e42ae2f2b2f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-tiUFZY4f-K"
      },
      "source": [
        "# Load Kaggle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "monfBu9VkRiX",
        "outputId": "c3fa40e9-e1c1-4ac2-f053-9cef0843da88"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=aabb8654eae694450fdd46a36555e01fcf9db8979f81c9a189f162f09ea7fc68\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRz9kX3oBOfU",
        "outputId": "418c1c68-c07d-420b-c6b7-7447de02db30"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ptAtQji3sg",
        "outputId": "fb600772-22e2-4f17-f112-e1c5d79cd0ca"
      },
      "source": [
        "base_dir = 'drive/MyDrive/Documents/Project/ECE228'\n",
        "Path(base_dir).ls()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('drive/MyDrive/Documents/Project/ECE228/kaggle.json'),\n",
              " PosixPath('drive/MyDrive/Documents/Project/ECE228/histopathologic-cancer-detection.zip'),\n",
              " PosixPath('drive/MyDrive/Documents/Project/ECE228/model.h5')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU5UT8UCi8J_",
        "outputId": "241f4bd2-7f89-4ac1-d1c5-7050ad06bd9b"
      },
      "source": [
        "#!kaggle competitions download -c histopathologic-cancer-detection -p \"{base_dir}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading histopathologic-cancer-detection.zip to drive/MyDrive/Documents/Project/ECE228\n",
            "100% 6.31G/6.31G [01:33<00:00, 52.1MB/s]\n",
            "100% 6.31G/6.31G [01:36<00:00, 70.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsNPBcLnF5-E"
      },
      "source": [
        "!unzip 'drive/MyDrive/Documents/Project/ECE228/histopathologic-cancer-detection.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-dIJgwG4jjR"
      },
      "source": [
        "# Transfer data for flow_from_directory call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHFiyngLj3Nb"
      },
      "source": [
        "from shutil import copyfile"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLPiOZG4kOBr"
      },
      "source": [
        "folders = ['train', 'test']\n",
        "labels = ['0', '1']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agQznsazquqm"
      },
      "source": [
        "!mv sample_submission.csv test_labels.csv"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcf0fhCDMbv"
      },
      "source": [
        "!mkdir -p \"dataset_folder/test/0\"\n",
        "!mkdir -p \"dataset_folder/test/1\"\n",
        "!mkdir -p \"dataset_folder/train/0\"\n",
        "!mkdir -p \"dataset_folder/train/1\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS40IiauCpy2"
      },
      "source": [
        "for folder in folders:\n",
        "    df = pd.read_csv('{}_labels.csv'.format(folder))\n",
        "    for filename, label in zip(df['id'], df['label']):\n",
        "        copyfile('{}/{}.tif'.format(folder, filename), \n",
        "                 '{}/{}/{}/{}.tif'.format('dataset_folder', folder, label, filename))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lVmOMIhY7yY"
      },
      "source": [
        "# Reference Notebook Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSV0j-y9Y7NT"
      },
      "source": [
        "tfms = get_transforms(do_flip=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4zYBeL1ZI3K"
      },
      "source": [
        "bs=64 # also the default batch size\n",
        "data = ImageDataBunch.from_csv('.',\n",
        "    ds_tfms=tfms, \n",
        "    size=224, \n",
        "    suffix=\".tif\",\n",
        "    folder=\"train\", \n",
        "    test=\"test\",\n",
        "    csv_labels=\"train_labels.csv\", \n",
        "    bs=bs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHvrdCDazDRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239a8bc8-7115-4347-82f9-b607e44670c5"
      },
      "source": [
        "data.normalize(imagenet_stats)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageDataBunch;\n",
              "\n",
              "Train: LabelList (176020 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "0,1,0,0,0\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (44005 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "0,1,0,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (57458 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_mQ1pvgOXr8"
      },
      "source": [
        "data.one_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8NYp9z0y-DD",
        "outputId": "a078da55-b886-4c32-8f92-6ff906e74c59"
      },
      "source": [
        "data"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageDataBunch;\n",
              "\n",
              "Train: LabelList (176020 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "0,0,0,0,0\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (44005 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "1,0,0,1,0\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (57458 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJDVCMOoZUEU"
      },
      "source": [
        "learn = cnn_learner(data, models.resnet50, metrics=error_rate, callback_fns=ShowGraph)#.to_fp16()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfn_rGTdZV8C"
      },
      "source": [
        "learn.summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNujIDqt4HBW",
        "outputId": "0c1be28f-3f82-4100-b3fc-b7749ba896d2"
      },
      "source": [
        "!pip install onnx"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/9b/54c950d3256e27f970a83cd0504efb183a24312702deed0179453316dbd0/onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx) (56.1.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kFgpEL14Tu_",
        "outputId": "e5b7d5b8-b93a-4a61-d1c2-f7d407083dfe"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbZacNXS4Wz1",
        "outputId": "e28c04f9-c372-48e0-b358-ecc403d5cfb5"
      },
      "source": [
        "!pip install git+https://github.com/onnx/onnx-tensorflow.git"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/onnx/onnx-tensorflow.git\n",
            "  Cloning https://github.com/onnx/onnx-tensorflow.git to /tmp/pip-req-build-zbslp0t_\n",
            "  Running command git clone -q https://github.com/onnx/onnx-tensorflow.git /tmp/pip-req-build-zbslp0t_\n",
            "Requirement already satisfied (use --upgrade to upgrade): onnx-tf==1.8.0 from git+https://github.com/onnx/onnx-tensorflow.git in ./onnx-tensorflow\n",
            "Requirement already satisfied: onnx>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (1.9.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (3.13)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.12.4)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons->onnx-tf==1.8.0) (2.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.8.0->onnx-tf==1.8.0) (56.1.0)\n",
            "Building wheels for collected packages: onnx-tf\n",
            "  Building wheel for onnx-tf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx-tf: filename=onnx_tf-1.8.0-cp37-none-any.whl size=219689 sha256=962d0117318f694d5b1313c686fa53628529c1385e09e7468a49f75d8335b01a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mac_r0q4/wheels/54/24/31/8873b33d2d560efdfa1ed6f346df67ef793b1897358705a480\n",
            "Successfully built onnx-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN00YIM68Wuf",
        "outputId": "0c2d35e6-8fcd-41ea-fefd-f014468f1fc6"
      },
      "source": [
        "!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e ."
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'onnx-tensorflow'...\n",
            "remote: Enumerating objects: 6136, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 6136 (delta 45), reused 33 (delta 18), pack-reused 6051\u001b[K\n",
            "Receiving objects: 100% (6136/6136), 1.87 MiB | 13.13 MiB/s, done.\n",
            "Resolving deltas: 100% (4770/4770), done.\n",
            "Obtaining file:///content/onnx-tensorflow\n",
            "Requirement already satisfied: onnx>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (1.9.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (3.13)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons->onnx-tf==1.8.0) (2.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.8.0->onnx-tf==1.8.0) (56.1.0)\n",
            "Installing collected packages: onnx-tf\n",
            "  Found existing installation: onnx-tf 1.8.0\n",
            "    Can't uninstall 'onnx-tf'. No files were found to uninstall.\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ7-P0gTAwR3",
        "outputId": "c0ad7d7b-0ed0-49c6-c004-527bf2ca7178"
      },
      "source": [
        "%cd onnx-tensorflow/"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/onnx-tensorflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[autoreload of onnx_tf failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ModuleNotFoundError: spec not found for the module 'onnx_tf'\n",
            "]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiwOeiCT7pTi"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import onnx\n",
        "import onnx_tf\n",
        "from onnx_tf.backend import prepare"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYf-j3m15Ivk"
      },
      "source": [
        "dummy_input = Variable(torch.randn(1, 3, 224, 224))\n",
        "torch.onnx.export(learn.model, dummy_input, \"/content/dummy.onnx\", input_names=['test_input'], output_names=['test_output'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WesBNObf7YL0"
      },
      "source": [
        "tf_rep = prepare(onnx.load('/content/dummy.onnx'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx3EnXBdBx0d",
        "outputId": "824f772b-4a3c-4a95-ee86-5642945b7656"
      },
      "source": [
        "tf_rep.export_graph('/content/dummy_model')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/dummy_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/dummy_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx6LdTTIELy8",
        "outputId": "8b32b567-7017-4440-b4cb-31611a6a525e"
      },
      "source": [
        "converted_model = tf.keras.models.load_model('/content/dummy_model')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzmYN0owEWQO",
        "outputId": "b82752bb-65f7-4415-e11c-1863235fda7a"
      },
      "source": [
        "type(converted_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWJQLwBRGCzw"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDQSFsHfTlwy"
      },
      "source": [
        "### TODO: \n",
        " * Fit generator on input sample (done with preprocessing function)\n",
        " * Apply learned params to test data (create another generator for test and apply same preprocessing function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di4J9q4tFvDX"
      },
      "source": [
        "new_base_dir = 'dataset_folder'\n",
        "training_sub_path = 'train'\n",
        "test_sub_path = 'test'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E4g2E6d-zaA"
      },
      "source": [
        "#IMG_SIZE = (96, 96)\n",
        "\"\"\"\n",
        "Images in the target PCam dataset are square images 96x96. \n",
        "However, when bringing a pre-trained ImageNet model into our\n",
        "network, which was trained on larger images, we need to set\n",
        "the size accordingly to respect the image sizes in that dataset.\n",
        "\"\"\"\n",
        "IMG_SIZE = (224, 224) \n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k4QVBZuaU8V",
        "outputId": "6f18ac20-25dc-4cc6-b7d2-a39cb1836d35"
      },
      "source": [
        "imagenet_stats"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GB0eddZfz8o"
      },
      "source": [
        "def custom_norm(x, mean=None, std=None):\n",
        "  if mean is None:\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "  if std is None:\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "  mean, std = np.array(mean), np.array(std)\n",
        "  image = np.array(x)\n",
        "  \n",
        "  return (image - mean[None, None, ...]) / std[None, None, ...]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZagDem6M_tVy"
      },
      "source": [
        "data_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    validation_split=0.2,\n",
        "                                    preprocessing_function=custom_norm)\n",
        "#,                                    featurewise_std_normalization=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYZHe2aRGRbE"
      },
      "source": [
        "data_generator = ImageDataGenerator(rotation_range=90, \n",
        "                                    width_shift_range=[0.2, -0.2], \n",
        "                                    height_shift_range=[0.2, -0.2], \n",
        "                                    brightness_range=[0.3, 1], \n",
        "                                    zoom_range=[0.5, 1], \n",
        "                                    horizontal_flip=True, \n",
        "                                    vertical_flip=True, \n",
        "                                    channel_shift_range=150.0, \n",
        "                                    fill_mode='wrap', \n",
        "                                    validation_split=0.2,\n",
        "                                    rescale=1./255,\n",
        "                                    preprocessing_function=custom_norm)\n",
        "#,                                    featurewise_std_normalization=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd0F8Xg2GZzZ",
        "outputId": "24aaa745-70bc-44f1-a039-71a14b39a91e"
      },
      "source": [
        "train_data_iterator = data_generator.flow_from_directory('{}/{}'.format(new_base_dir, 'train'), \n",
        "                                                         target_size=(224, 224),\n",
        "                                                         class_mode='binary', \n",
        "                                                         subset='training', \n",
        "                                                         batch_size=BATCH_SIZE)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 176021 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgiD0KIaGbDa",
        "outputId": "f4f122bf-9404-45b5-f6f6-25b93ecbb73e"
      },
      "source": [
        "validation_data_iterator = data_generator.flow_from_directory('{}/{}'.format(new_base_dir, 'train'), \n",
        "                                                              target_size=(224, 224),\n",
        "                                                              class_mode='binary', \n",
        "                                                              subset='validation', \n",
        "                                                              batch_size=BATCH_SIZE)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 44004 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kVhq_ASGcQF"
      },
      "source": [
        "STEP_SIZE_TRAIN = train_data_iterator.n//train_data_iterator.batch_size\n",
        "STEP_SIZE_VALIDATION = validation_data_iterator.n//validation_data_iterator.batch_size"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGoxNMKuGfM0"
      },
      "source": [
        "# Load Backbone model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjAdj6FtGelF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8502f96a-2aa4-4440-f7d2-59eebb0823aa"
      },
      "source": [
        "conv_base = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwFyR-vtivVv"
      },
      "source": [
        "conv_base.Trainable=True\n",
        "\n",
        "set_trainable=False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'res5a_branch2a':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BJAHOnS_2JY"
      },
      "source": [
        "for layer in conv_base.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diuf5LCrGp2i"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_data_iterator))\n",
        "#feature_batch = base_model(image_batch)\n",
        "#print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAZihPnvpc4Q"
      },
      "source": [
        "image_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkzIt_HaGwtZ"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9NGYaiOM4OF"
      },
      "source": [
        "# Add Top Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueFuZ7XtOlGh"
      },
      "source": [
        "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "x = conv_base(inputs, training=False)\n",
        "avgpool = tf.keras.layers.AveragePooling2D((3,3), padding=\"same\")(x)\n",
        "maxpool = tf.keras.layers.MaxPooling2D((3,3), padding=\"same\")(x)\n",
        "x = tf.keras.layers.Concatenate()([avgpool, maxpool])\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1)(x)\n",
        "model = tf.keras.Model(inputs, x)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Ekdh2L8YRa",
        "outputId": "48851775-0ffc-4935-b68f-e1ec3c4e2af3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "resnet50 (Functional)           (None, 7, 7, 2048)   23587712    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 3, 3, 2048)   0           resnet50[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 3, 3, 2048)   0           resnet50[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 4096)   0           average_pooling2d_1[0][0]        \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 36864)        0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 36864)        147456      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 36864)        0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          18874880    dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 512)          0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            513         dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 42,612,609\n",
            "Trainable params: 18,950,145\n",
            "Non-trainable params: 23,662,464\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM328swqGTtX"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFOopg6OF-t4"
      },
      "source": [
        "# Find Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDxcubrmL64L"
      },
      "source": [
        "\"\"\"\n",
        "https://github.com/surmenok/keras_lr_finder/blob/master/keras_lr_finder/lr_finder.py\n",
        "\"\"\"\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LRFinder:\n",
        "    \"\"\"\n",
        "    Plots the change of the loss function of a Keras model when the learning rate is exponentially increasing.\n",
        "    See for details:\n",
        "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.losses = []\n",
        "        self.lrs = []\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        # Log the learning rate\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.lrs.append(lr)\n",
        "\n",
        "        # Log the loss\n",
        "        loss = logs['loss']\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        # Check whether the loss got too large or NaN\n",
        "        if batch > 5 and (math.isnan(loss) or loss > self.best_loss * 4):\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if loss < self.best_loss:\n",
        "            self.best_loss = loss\n",
        "\n",
        "        # Increase the learning rate for the next batch\n",
        "        lr *= self.lr_mult\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "\n",
        "    def find(self, x_train, y_train, start_lr, end_lr, batch_size=64, epochs=1, **kw_fit):\n",
        "        # If x_train contains data for multiple inputs, use length of the first input.\n",
        "        # Assumption: the first element in the list is single input; NOT a list of inputs.\n",
        "        N = x_train[0].shape[0] if isinstance(x_train, list) else x_train.shape[0]\n",
        "\n",
        "        # Compute number of batches and LR multiplier\n",
        "        num_batches = epochs * N / batch_size\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(num_batches))\n",
        "        # Save weights into a file\n",
        "        initial_weights = self.model.get_weights()\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.lr, start_lr)\n",
        "\n",
        "        callback = LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs))\n",
        "\n",
        "        self.model.fit(x_train, y_train,\n",
        "                       batch_size=batch_size, epochs=epochs,\n",
        "                       callbacks=[callback],\n",
        "                       **kw_fit)\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.set_weights(initial_weights)\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.lr, original_lr)\n",
        "\n",
        "    def find_generator(self, generator, start_lr, end_lr, epochs=1, steps_per_epoch=None, **kw_fit):\n",
        "        if steps_per_epoch is None:\n",
        "            try:\n",
        "                steps_per_epoch = len(generator)\n",
        "            except (ValueError, NotImplementedError) as e:\n",
        "                raise e('`steps_per_epoch=None` is only valid for a'\n",
        "                        ' generator based on the '\n",
        "                        '`keras.utils.Sequence`'\n",
        "                        ' class. Please specify `steps_per_epoch` '\n",
        "                        'or use the `keras.utils.Sequence` class.')\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(epochs * steps_per_epoch))\n",
        "\n",
        "        # Save weights into a file\n",
        "        initial_weights = self.model.get_weights()\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.lr, start_lr)\n",
        "\n",
        "        callback = LambdaCallback(on_batch_end=lambda batch,\n",
        "                                                      logs: self.on_batch_end(batch, logs))\n",
        "\n",
        "        self.model.fit_generator(generator=generator,\n",
        "                                 epochs=epochs,\n",
        "                                 steps_per_epoch=steps_per_epoch,\n",
        "                                 callbacks=[callback],\n",
        "                                 **kw_fit)\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.set_weights(initial_weights)\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.lr, original_lr)\n",
        "\n",
        "    def plot_loss(self, n_skip_beginning=10, n_skip_end=5, x_scale='log'):\n",
        "        \"\"\"\n",
        "        Plots the loss.\n",
        "        Parameters:\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "        \"\"\"\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], self.losses[n_skip_beginning:-n_skip_end])\n",
        "        plt.xscale(x_scale)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss_change(self, sma=1, n_skip_beginning=10, n_skip_end=5, y_lim=(-0.01, 0.01)):\n",
        "        \"\"\"\n",
        "        Plots rate of change of the loss function.\n",
        "        Parameters:\n",
        "            sma - number of batches for simple moving average to smooth out the curve.\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "            y_lim - limits for the y axis.\n",
        "        \"\"\"\n",
        "        derivatives = self.get_derivatives(sma)[n_skip_beginning:-n_skip_end]\n",
        "        lrs = self.lrs[n_skip_beginning:-n_skip_end]\n",
        "        plt.ylabel(\"rate of loss change\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(lrs, derivatives)\n",
        "        plt.xscale('log')\n",
        "        plt.ylim(y_lim)\n",
        "        plt.show()\n",
        "\n",
        "    def get_derivatives(self, sma):\n",
        "        assert sma >= 1\n",
        "        derivatives = [0] * sma\n",
        "        for i in range(sma, len(self.lrs)):\n",
        "            derivatives.append((self.losses[i] - self.losses[i - sma]) / sma)\n",
        "        return derivatives\n",
        "\n",
        "    def get_best_lr(self, sma, n_skip_beginning=10, n_skip_end=5):\n",
        "        derivatives = self.get_derivatives(sma)\n",
        "        best_der_idx = np.argmin(derivatives[n_skip_beginning:-n_skip_end])\n",
        "        return self.lrs[n_skip_beginning:-n_skip_end][best_der_idx]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs-AlS_gGFJf"
      },
      "source": [
        "lr_finder = LRFinder(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZfD8xsHMgas",
        "outputId": "61062f8a-841c-401e-f15d-652df61748e7"
      },
      "source": [
        "lr_finder.find_generator(train_data_iterator, start_lr=0.00001, end_lr=1, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2751/2751 [==============================] - 923s 329ms/step - loss: 1.6837\n",
            "Epoch 2/2\n",
            "2751/2751 [==============================] - 109s 40ms/step - loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "DdYtA_8RGnbr",
        "outputId": "173f6393-a923-4a39-898c-48a3951f3a91"
      },
      "source": [
        "lr_finder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1nTMkw44rH9",
        "outputId": "152d5c8e-b509-4fba-c998-27026074b2c4"
      },
      "source": [
        "lr_finder.get_best_lr(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003162277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwU8MFfzUGug"
      },
      "source": [
        "# Fit one cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJdASdKDUI3O"
      },
      "source": [
        "\"\"\"\n",
        "https://www.avanwyk.com/tensorflow-2-super-convergence-with-the-1cycle-policy/\n",
        "\"\"\"\n",
        "\n",
        "class CosineAnnealer:\n",
        "    def __init__(self, start, end, steps):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.steps = steps\n",
        "        self.n = 0\n",
        "        \n",
        "    def step(self):\n",
        "        self.n += 1\n",
        "        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n",
        "        return self.end + (self.start - self.end) / 2. * cos\n",
        "\n",
        "\n",
        "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n",
        "        super(OneCycleScheduler, self).__init__()\n",
        "        lr_min = lr_max / div_factor\n",
        "        final_lr = lr_max / (div_factor * 1e4)\n",
        "        phase_1_steps = steps * phase_1_pct\n",
        "        phase_2_steps = steps - phase_1_steps\n",
        "        \n",
        "        self.phase_1_steps = phase_1_steps\n",
        "        self.phase_2_steps = phase_2_steps\n",
        "        self.phase = 0\n",
        "        self.step = 0\n",
        "        \n",
        "        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n",
        "                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n",
        "        \n",
        "        self.lrs = []\n",
        "        self.moms = []\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.phase = 0\n",
        "        self.step = 0\n",
        "\n",
        "        self.set_lr(self.lr_schedule().start)\n",
        "        self.set_momentum(self.mom_schedule().start)\n",
        "        \n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        self.lrs.append(self.get_lr())\n",
        "        self.moms.append(self.get_momentum())\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        self.step += 1\n",
        "        if self.step >= self.phase_1_steps:\n",
        "            self.phase = 1\n",
        "            \n",
        "        self.set_lr(self.lr_schedule().step())\n",
        "        self.set_momentum(self.mom_schedule().step())\n",
        "        \n",
        "    def get_lr(self):\n",
        "        try:\n",
        "            return tf.keras.backend.get_value(self.model.optimizer.lr)\n",
        "        except AttributeError:\n",
        "            return None\n",
        "        \n",
        "    def get_momentum(self):\n",
        "        try:\n",
        "            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n",
        "        except AttributeError:\n",
        "            return None\n",
        "        \n",
        "    def set_lr(self, lr):\n",
        "        try:\n",
        "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        except AttributeError:\n",
        "            pass # ignore\n",
        "        \n",
        "    def set_momentum(self, mom):\n",
        "        try:\n",
        "            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n",
        "        except AttributeError:\n",
        "            pass # ignore\n",
        "\n",
        "    def lr_schedule(self):\n",
        "        return self.phases[self.phase][0]\n",
        "    \n",
        "    def mom_schedule(self):\n",
        "        return self.phases[self.phase][1]\n",
        "    \n",
        "    def plot(self):\n",
        "        ax = plt.subplot(1, 2, 1)\n",
        "        ax.plot(self.lrs)\n",
        "        ax.set_title('Learning Rate')\n",
        "        ax = plt.subplot(1, 2, 2)\n",
        "        ax.plot(self.moms)\n",
        "        ax.set_title('Momentum')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smE5yk059U61"
      },
      "source": [
        "epochs = 30\n",
        "#lr = lr_finder.get_best_lr(1)\n",
        "lr = 0.003162277\n",
        "steps = STEP_SIZE_TRAIN * epochs\n",
        "lr_schedule = OneCycleScheduler(lr, steps)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vavJ4Zex9fY2",
        "outputId": "646e912f-6818-49d9-975b-a4a43ef999dc"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data_iterator, validation_data=validation_data_iterator, epochs=epochs, callbacks=[lr_schedule], verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2751/2751 [==============================] - 801s 281ms/step - loss: 3.3479 - accuracy: 0.7691 - val_loss: 3.0273 - val_accuracy: 0.7888\n",
            "Epoch 2/30\n",
            "2751/2751 [==============================] - 755s 274ms/step - loss: 3.2289 - accuracy: 0.7753 - val_loss: 3.0673 - val_accuracy: 0.7868\n",
            "Epoch 3/30\n",
            "2751/2751 [==============================] - 753s 274ms/step - loss: 3.4025 - accuracy: 0.7653 - val_loss: 3.1915 - val_accuracy: 0.7802\n",
            "Epoch 4/30\n",
            "2751/2751 [==============================] - 749s 272ms/step - loss: 3.2324 - accuracy: 0.7763 - val_loss: 3.0379 - val_accuracy: 0.7912\n",
            "Epoch 5/30\n",
            "2751/2751 [==============================] - 756s 275ms/step - loss: 3.3805 - accuracy: 0.7703 - val_loss: 2.9872 - val_accuracy: 0.7982\n",
            "Epoch 6/30\n",
            "2751/2751 [==============================] - 753s 274ms/step - loss: 3.3093 - accuracy: 0.7768 - val_loss: 3.3475 - val_accuracy: 0.7761\n",
            "Epoch 7/30\n",
            "2751/2751 [==============================] - 752s 273ms/step - loss: 3.3492 - accuracy: 0.7755 - val_loss: 3.4932 - val_accuracy: 0.7656\n",
            "Epoch 8/30\n",
            "2751/2751 [==============================] - 764s 278ms/step - loss: 3.3926 - accuracy: 0.7745 - val_loss: 3.3232 - val_accuracy: 0.7800\n",
            "Epoch 9/30\n",
            "2751/2751 [==============================] - 767s 279ms/step - loss: 3.2764 - accuracy: 0.7836 - val_loss: 3.0893 - val_accuracy: 0.7964\n",
            "Epoch 10/30\n",
            "2751/2751 [==============================] - 764s 278ms/step - loss: 3.3954 - accuracy: 0.7758 - val_loss: 3.3128 - val_accuracy: 0.7811\n",
            "Epoch 11/30\n",
            "2751/2751 [==============================] - 760s 276ms/step - loss: 3.1760 - accuracy: 0.7904 - val_loss: 2.9873 - val_accuracy: 0.8034\n",
            "Epoch 12/30\n",
            "2751/2751 [==============================] - 765s 278ms/step - loss: 3.1721 - accuracy: 0.7909 - val_loss: 3.2902 - val_accuracy: 0.7836\n",
            "Epoch 13/30\n",
            "2751/2751 [==============================] - 761s 276ms/step - loss: 3.2236 - accuracy: 0.7876 - val_loss: 3.1243 - val_accuracy: 0.7942\n",
            "Epoch 14/30\n",
            "2751/2751 [==============================] - 765s 278ms/step - loss: 3.1121 - accuracy: 0.7952 - val_loss: 2.9952 - val_accuracy: 0.8029\n",
            "Epoch 15/30\n",
            "2751/2751 [==============================] - 812s 295ms/step - loss: 3.0903 - accuracy: 0.7968 - val_loss: 2.9734 - val_accuracy: 0.8043\n",
            "Epoch 16/30\n",
            "2751/2751 [==============================] - 752s 273ms/step - loss: 3.2000 - accuracy: 0.7898 - val_loss: 2.9791 - val_accuracy: 0.8044\n",
            "Epoch 17/30\n",
            "2751/2751 [==============================] - 748s 272ms/step - loss: 3.0565 - accuracy: 0.7991 - val_loss: 3.0211 - val_accuracy: 0.8018\n",
            "Epoch 18/30\n",
            "2751/2751 [==============================] - 749s 272ms/step - loss: 3.2001 - accuracy: 0.7897 - val_loss: 2.9437 - val_accuracy: 0.8066\n",
            "Epoch 19/30\n",
            "2751/2751 [==============================] - 749s 272ms/step - loss: 3.0747 - accuracy: 0.7981 - val_loss: 2.9768 - val_accuracy: 0.8045\n",
            "Epoch 20/30\n",
            "2751/2751 [==============================] - 747s 272ms/step - loss: 3.0105 - accuracy: 0.8023 - val_loss: 2.9762 - val_accuracy: 0.8048\n",
            "Epoch 21/30\n",
            "2751/2751 [==============================] - 753s 274ms/step - loss: 2.9893 - accuracy: 0.8039 - val_loss: 2.9703 - val_accuracy: 0.8050\n",
            "Epoch 22/30\n",
            "2751/2751 [==============================] - 753s 274ms/step - loss: 3.0499 - accuracy: 0.7996 - val_loss: 2.8628 - val_accuracy: 0.8121\n",
            "Epoch 23/30\n",
            "2751/2751 [==============================] - 751s 273ms/step - loss: 2.9198 - accuracy: 0.8084 - val_loss: 2.8371 - val_accuracy: 0.8137\n",
            "Epoch 24/30\n",
            "2751/2751 [==============================] - 748s 272ms/step - loss: 2.8928 - accuracy: 0.8100 - val_loss: 2.7957 - val_accuracy: 0.8164\n",
            "Epoch 25/30\n",
            "2751/2751 [==============================] - 748s 272ms/step - loss: 2.8789 - accuracy: 0.8110 - val_loss: 2.8090 - val_accuracy: 0.8155\n",
            "Epoch 26/30\n",
            "2751/2751 [==============================] - 753s 274ms/step - loss: 2.8624 - accuracy: 0.8120 - val_loss: 2.7975 - val_accuracy: 0.8166\n",
            "Epoch 27/30\n",
            "2751/2751 [==============================] - 752s 273ms/step - loss: 2.8508 - accuracy: 0.8130 - val_loss: 2.7958 - val_accuracy: 0.8163\n",
            "Epoch 28/30\n",
            " 156/2751 [>.............................] - ETA: 9:21 - loss: 2.7932 - accuracy: 0.8171"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5J7ldZpTBuB"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWDnceyUTHxY"
      },
      "source": [
        "model.save('{}/{}'.format(base_dir, 'model.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjb8cP8XrnaI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfYE7PPRTYhv"
      },
      "source": [
        "# References\n",
        "\n",
        "  * https://github.com/priya-dwivedi/Deep-Learning/blob/master/resnet_keras/Residual_Networks_yourself.ipynb"
      ]
    }
  ]
}
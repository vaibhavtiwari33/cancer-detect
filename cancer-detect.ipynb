{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE228_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x-tiUFZY4f-K",
        "p-dIJgwG4jjR",
        "4lVmOMIhY7yY",
        "RWJQLwBRGCzw",
        "sGoxNMKuGfM0",
        "W9NGYaiOM4OF",
        "PFOopg6OF-t4"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e668eb463b2a4906a6a3517d6737f16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f517fdbd8924511b162f7d1ab753bde",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_966b4c8453bf422baf715c67a1bf7baf",
              "IPY_MODEL_74981cb16411480388948a80882bb0d9"
            ]
          }
        },
        "4f517fdbd8924511b162f7d1ab753bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "966b4c8453bf422baf715c67a1bf7baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc949081bbdf4a47843480c16eb99492",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dfee6148cb3467eabe0788a37bc745f"
          }
        },
        "74981cb16411480388948a80882bb0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b0467bd2c474dc1bf03842fc2e79021",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:09&lt;00:00, 11.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc505490d253454ea3578d6199618d5b"
          }
        },
        "cc949081bbdf4a47843480c16eb99492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dfee6148cb3467eabe0788a37bc745f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b0467bd2c474dc1bf03842fc2e79021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc505490d253454ea3578d6199618d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavtiwari33/cancer-detect/blob/main/cancer-detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX8JhWl3iwHG"
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "# Import Libraries here\n",
        "import os\n",
        "import json \n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wUC1Mtc4_bJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM8DlN_WG5Xv",
        "outputId": "dae2c9f7-9167-4598-f529-9e42ae2f2b2f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-tiUFZY4f-K"
      },
      "source": [
        "# Load Kaggle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "monfBu9VkRiX",
        "outputId": "c3fa40e9-e1c1-4ac2-f053-9cef0843da88"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=aabb8654eae694450fdd46a36555e01fcf9db8979f81c9a189f162f09ea7fc68\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRz9kX3oBOfU",
        "outputId": "5959e179-25ab-47d4-ff1f-a7fe3dac70af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ptAtQji3sg",
        "outputId": "fc198fbf-8863-44ff-cbcb-3f22df168324"
      },
      "source": [
        "base_dir = 'drive/MyDrive/Documents/Project/ECE228'\n",
        "Path(base_dir).ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('drive/MyDrive/Documents/Project/ECE228/kaggle.json'),\n",
              " PosixPath('drive/MyDrive/Documents/Project/ECE228/histopathologic-cancer-detection.zip')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU5UT8UCi8J_",
        "outputId": "241f4bd2-7f89-4ac1-d1c5-7050ad06bd9b"
      },
      "source": [
        "#!kaggle competitions download -c histopathologic-cancer-detection -p \"{base_dir}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading histopathologic-cancer-detection.zip to drive/MyDrive/Documents/Project/ECE228\n",
            "100% 6.31G/6.31G [01:33<00:00, 52.1MB/s]\n",
            "100% 6.31G/6.31G [01:36<00:00, 70.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsNPBcLnF5-E"
      },
      "source": [
        "!unzip 'drive/MyDrive/Documents/Project/ECE228/histopathologic-cancer-detection.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-dIJgwG4jjR"
      },
      "source": [
        "# Transfer data for flow_from_directory call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHFiyngLj3Nb"
      },
      "source": [
        "from shutil import copyfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLPiOZG4kOBr"
      },
      "source": [
        "folders = ['train', 'test']\n",
        "labels = ['0', '1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agQznsazquqm"
      },
      "source": [
        "!mv sample_submission.csv test_labels.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcf0fhCDMbv"
      },
      "source": [
        "!mkdir -p \"dataset_folder/test/0\"\n",
        "!mkdir -p \"dataset_folder/test/1\"\n",
        "!mkdir -p \"dataset_folder/train/0\"\n",
        "!mkdir -p \"dataset_folder/train/1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS40IiauCpy2"
      },
      "source": [
        "for folder in folders:\n",
        "    df = pd.read_csv('{}_labels.csv'.format(folder))\n",
        "    for filename, label in zip(df['id'], df['label']):\n",
        "        copyfile('{}/{}.tif'.format(folder, filename), \n",
        "                 '{}/{}/{}/{}.tif'.format('dataset_folder', folder, label, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lVmOMIhY7yY"
      },
      "source": [
        "# Reference Notebook Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSV0j-y9Y7NT"
      },
      "source": [
        "tfms = get_transforms(do_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4zYBeL1ZI3K"
      },
      "source": [
        "bs=64 # also the default batch size\n",
        "data = ImageDataBunch.from_csv('.',\n",
        "    ds_tfms=tfms, \n",
        "    size=224, \n",
        "    suffix=\".tif\",\n",
        "    folder=\"train\", \n",
        "    test=\"test\",\n",
        "    csv_labels=\"train_labels.csv\", \n",
        "    bs=bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHvrdCDazDRr"
      },
      "source": [
        "data.normalize(imagenet_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_mQ1pvgOXr8",
        "outputId": "8c06db85-30c6-4f72-8408-d1c6d36c640a"
      },
      "source": [
        "data.one_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[0.5159, 0.3543, 0.2815,  ..., 0.9424, 0.9424, 0.9421],\n",
              "           [0.5206, 0.4106, 0.3402,  ..., 0.9460, 0.9456, 0.9443],\n",
              "           [0.5517, 0.4785, 0.4174,  ..., 0.9460, 0.9459, 0.9452],\n",
              "           ...,\n",
              "           [0.9509, 0.9523, 0.9525,  ..., 0.9497, 0.9496, 0.9493],\n",
              "           [0.9492, 0.9505, 0.9510,  ..., 0.9497, 0.9493, 0.9483],\n",
              "           [0.9474, 0.9489, 0.9497,  ..., 0.9497, 0.9491, 0.9476]],\n",
              " \n",
              "          [[0.3797, 0.2198, 0.1470,  ..., 0.9424, 0.9424, 0.9421],\n",
              "           [0.3815, 0.2715, 0.2004,  ..., 0.9460, 0.9456, 0.9443],\n",
              "           [0.4088, 0.3344, 0.2721,  ..., 0.9460, 0.9459, 0.9452],\n",
              "           ...,\n",
              "           [0.9509, 0.9523, 0.9525,  ..., 0.9497, 0.9496, 0.9493],\n",
              "           [0.9492, 0.9505, 0.9510,  ..., 0.9497, 0.9493, 0.9483],\n",
              "           [0.9474, 0.9489, 0.9497,  ..., 0.9497, 0.9491, 0.9476]],\n",
              " \n",
              "          [[0.5168, 0.3638, 0.2988,  ..., 0.9349, 0.9349, 0.9346],\n",
              "           [0.5233, 0.4198, 0.3559,  ..., 0.9385, 0.9381, 0.9368],\n",
              "           [0.5578, 0.4897, 0.4334,  ..., 0.9385, 0.9384, 0.9377],\n",
              "           ...,\n",
              "           [0.9435, 0.9448, 0.9450,  ..., 0.9422, 0.9421, 0.9418],\n",
              "           [0.9417, 0.9431, 0.9435,  ..., 0.9422, 0.9418, 0.9409],\n",
              "           [0.9400, 0.9414, 0.9422,  ..., 0.9422, 0.9416, 0.9401]]],\n",
              " \n",
              " \n",
              "         [[[0.5896, 0.5449, 0.4921,  ..., 0.9582, 0.9581, 0.9608],\n",
              "           [0.3628, 0.3355, 0.3071,  ..., 0.9626, 0.9615, 0.9626],\n",
              "           [0.2229, 0.1789, 0.1322,  ..., 0.9647, 0.9655, 0.9678],\n",
              "           ...,\n",
              "           [0.9996, 0.9998, 1.0000,  ..., 0.9967, 0.9989, 0.9558],\n",
              "           [1.0000, 1.0000, 0.9990,  ..., 1.0000, 0.9983, 0.9874],\n",
              "           [1.0000, 1.0000, 0.9980,  ..., 0.9846, 0.9699, 0.9550]],\n",
              " \n",
              "          [[0.5108, 0.4780, 0.4376,  ..., 0.9584, 0.9575, 0.9569],\n",
              "           [0.2818, 0.2651, 0.2479,  ..., 0.9626, 0.9610, 0.9599],\n",
              "           [0.1273, 0.0967, 0.0681,  ..., 0.9647, 0.9655, 0.9676],\n",
              "           ...,\n",
              "           [0.9874, 0.9916, 0.9959,  ..., 0.9599, 0.9524, 0.8934],\n",
              "           [0.9865, 0.9898, 0.9919,  ..., 0.9646, 0.9454, 0.9189],\n",
              "           [0.9847, 0.9868, 0.9871,  ..., 0.9426, 0.9134, 0.8854]],\n",
              " \n",
              "          [[0.5913, 0.5520, 0.5056,  ..., 0.9531, 0.9473, 0.9457],\n",
              "           [0.3648, 0.3406, 0.3162,  ..., 0.9611, 0.9568, 0.9542],\n",
              "           [0.2242, 0.1809, 0.1361,  ..., 0.9647, 0.9655, 0.9673],\n",
              "           ...,\n",
              "           [0.9978, 0.9989, 0.9999,  ..., 0.9932, 0.9945, 0.9451],\n",
              "           [0.9980, 0.9986, 0.9981,  ..., 0.9982, 0.9923, 0.9750],\n",
              "           [0.9980, 0.9981, 0.9961,  ..., 0.9772, 0.9583, 0.9386]]],\n",
              " \n",
              " \n",
              "         [[[0.2610, 0.2966, 0.3312,  ..., 0.5617, 0.5929, 0.6267],\n",
              "           [0.3473, 0.4091, 0.4599,  ..., 0.5144, 0.5287, 0.5455],\n",
              "           [0.4370, 0.5333, 0.6019,  ..., 0.4521, 0.4600, 0.4649],\n",
              "           ...,\n",
              "           [0.6545, 0.6996, 0.7462,  ..., 0.5530, 0.5108, 0.4708],\n",
              "           [0.6709, 0.6939, 0.7209,  ..., 0.6017, 0.5604, 0.5172],\n",
              "           [0.6918, 0.6806, 0.6735,  ..., 0.6462, 0.6068, 0.5642]],\n",
              " \n",
              "          [[0.1279, 0.1548, 0.1804,  ..., 0.4405, 0.4636, 0.4886],\n",
              "           [0.2214, 0.2698, 0.3063,  ..., 0.3948, 0.4034, 0.4141],\n",
              "           [0.3130, 0.3894, 0.4372,  ..., 0.3344, 0.3379, 0.3381],\n",
              "           ...,\n",
              "           [0.4328, 0.4752, 0.5187,  ..., 0.3148, 0.2868, 0.2611],\n",
              "           [0.4445, 0.4675, 0.4940,  ..., 0.3587, 0.3320, 0.3030],\n",
              "           [0.4599, 0.4530, 0.4498,  ..., 0.3979, 0.3729, 0.3440]],\n",
              " \n",
              "          [[0.4515, 0.4630, 0.4738,  ..., 0.7204, 0.7339, 0.7493],\n",
              "           [0.5276, 0.5686, 0.5984,  ..., 0.6682, 0.6674, 0.6690],\n",
              "           [0.6107, 0.6925, 0.7451,  ..., 0.6033, 0.5993, 0.5919],\n",
              "           ...,\n",
              "           [0.7305, 0.7718, 0.8142,  ..., 0.6104, 0.5826, 0.5564],\n",
              "           [0.7505, 0.7655, 0.7844,  ..., 0.6561, 0.6285, 0.5983],\n",
              "           [0.7747, 0.7508, 0.7321,  ..., 0.6983, 0.6715, 0.6409]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0.3748, 0.3909, 0.4004,  ..., 0.3487, 0.3369, 0.3262],\n",
              "           [0.4536, 0.4319, 0.4232,  ..., 0.3499, 0.3254, 0.3082],\n",
              "           [0.4801, 0.4355, 0.4110,  ..., 0.3402, 0.2981, 0.2805],\n",
              "           ...,\n",
              "           [0.5746, 0.5637, 0.6137,  ..., 0.7363, 0.7276, 0.7113],\n",
              "           [0.5739, 0.5414, 0.5993,  ..., 0.6940, 0.7303, 0.7583],\n",
              "           [0.6262, 0.5934, 0.6378,  ..., 0.6747, 0.7129, 0.7565]],\n",
              " \n",
              "          [[0.2072, 0.2226, 0.2315,  ..., 0.1676, 0.1589, 0.1507],\n",
              "           [0.2791, 0.2566, 0.2470,  ..., 0.1682, 0.1450, 0.1284],\n",
              "           [0.2987, 0.2528, 0.2274,  ..., 0.1551, 0.1124, 0.0943],\n",
              "           ...,\n",
              "           [0.2529, 0.2429, 0.2878,  ..., 0.2791, 0.2454, 0.2034],\n",
              "           [0.2617, 0.2297, 0.2812,  ..., 0.2376, 0.2538, 0.2613],\n",
              "           [0.3306, 0.3001, 0.3358,  ..., 0.2295, 0.2469, 0.2710]],\n",
              " \n",
              "          [[0.6235, 0.6379, 0.6461,  ..., 0.6131, 0.6062, 0.5992],\n",
              "           [0.6891, 0.6680, 0.6589,  ..., 0.6152, 0.5942, 0.5789],\n",
              "           [0.7065, 0.6639, 0.6397,  ..., 0.6056, 0.5652, 0.5473],\n",
              "           ...,\n",
              "           [0.6551, 0.6453, 0.6864,  ..., 0.6787, 0.6513, 0.6152],\n",
              "           [0.6672, 0.6375, 0.6841,  ..., 0.6425, 0.6636, 0.6762],\n",
              "           [0.7331, 0.7038, 0.7381,  ..., 0.6374, 0.6610, 0.6904]]],\n",
              " \n",
              " \n",
              "         [[[0.8636, 0.7882, 0.7182,  ..., 0.6316, 0.7058, 0.7773],\n",
              "           [0.8645, 0.7565, 0.6521,  ..., 0.6196, 0.7215, 0.8060],\n",
              "           [0.8501, 0.7136, 0.5792,  ..., 0.6070, 0.7364, 0.8288],\n",
              "           ...,\n",
              "           [0.6258, 0.6370, 0.6495,  ..., 0.8323, 0.7958, 0.8340],\n",
              "           [0.6305, 0.6337, 0.6363,  ..., 0.8339, 0.8221, 0.8885],\n",
              "           [0.6451, 0.6551, 0.6645,  ..., 0.7997, 0.8243, 0.9261]],\n",
              " \n",
              "          [[0.6094, 0.5380, 0.4806,  ..., 0.3836, 0.4638, 0.5466],\n",
              "           [0.6065, 0.5112, 0.4241,  ..., 0.3697, 0.4782, 0.5765],\n",
              "           [0.5943, 0.4754, 0.3653,  ..., 0.3538, 0.4911, 0.6003],\n",
              "           ...,\n",
              "           [0.4096, 0.4224, 0.4364,  ..., 0.7455, 0.7153, 0.7598],\n",
              "           [0.4137, 0.4182, 0.4223,  ..., 0.7565, 0.7493, 0.8231],\n",
              "           [0.4287, 0.4401, 0.4511,  ..., 0.7273, 0.7569, 0.8683]],\n",
              " \n",
              "          [[0.8212, 0.7698, 0.7304,  ..., 0.6881, 0.7585, 0.8238],\n",
              "           [0.8243, 0.7518, 0.6846,  ..., 0.6893, 0.7873, 0.8661],\n",
              "           [0.8198, 0.7253, 0.6348,  ..., 0.6851, 0.8131, 0.9029],\n",
              "           ...,\n",
              "           [0.7020, 0.7090, 0.7171,  ..., 0.8728, 0.8511, 0.8903],\n",
              "           [0.7087, 0.7076, 0.7061,  ..., 0.8845, 0.8782, 0.9273],\n",
              "           [0.7246, 0.7297, 0.7343,  ..., 0.8648, 0.8833, 0.9509]]],\n",
              " \n",
              " \n",
              "         [[[0.9630, 0.9636, 0.9580,  ..., 0.9699, 0.9689, 0.9679],\n",
              "           [0.9677, 0.9684, 0.9621,  ..., 0.9699, 0.9689, 0.9678],\n",
              "           [0.9694, 0.9699, 0.9645,  ..., 0.9699, 0.9689, 0.9678],\n",
              "           ...,\n",
              "           [0.9689, 0.9689, 0.9689,  ..., 0.9345, 0.9316, 0.9287],\n",
              "           [0.9689, 0.9689, 0.9689,  ..., 0.9377, 0.9342, 0.9306],\n",
              "           [0.9689, 0.9689, 0.9689,  ..., 0.9469, 0.9459, 0.9450]],\n",
              " \n",
              "          [[0.9553, 0.9559, 0.9501,  ..., 0.9574, 0.9563, 0.9552],\n",
              "           [0.9603, 0.9609, 0.9543,  ..., 0.9574, 0.9563, 0.9552],\n",
              "           [0.9620, 0.9625, 0.9569,  ..., 0.9574, 0.9563, 0.9552],\n",
              "           ...,\n",
              "           [0.9563, 0.9563, 0.9563,  ..., 0.8377, 0.8371, 0.8366],\n",
              "           [0.9563, 0.9563, 0.9563,  ..., 0.8432, 0.8411, 0.8389],\n",
              "           [0.9563, 0.9563, 0.9563,  ..., 0.8574, 0.8572, 0.8570]],\n",
              " \n",
              "          [[0.9857, 0.9885, 0.9608,  ..., 0.9723, 0.9713, 0.9703],\n",
              "           [0.9890, 0.9915, 0.9643,  ..., 0.9723, 0.9713, 0.9703],\n",
              "           [0.9898, 0.9919, 0.9661,  ..., 0.9723, 0.9713, 0.9703],\n",
              "           ...,\n",
              "           [0.9713, 0.9713, 0.9713,  ..., 0.9213, 0.9172, 0.9131],\n",
              "           [0.9713, 0.9713, 0.9713,  ..., 0.9265, 0.9218, 0.9171],\n",
              "           [0.9713, 0.9713, 0.9713,  ..., 0.9374, 0.9360, 0.9346]]]]),\n",
              " tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8NYp9z0y-DD",
        "outputId": "71ab5638-4d1c-4e38-8154-3c526c539093"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageDataBunch;\n",
              "\n",
              "Train: LabelList (176020 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "0,1,0,0,0\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (44005 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "0,0,1,0,1\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (57458 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "e668eb463b2a4906a6a3517d6737f16c",
            "4f517fdbd8924511b162f7d1ab753bde",
            "966b4c8453bf422baf715c67a1bf7baf",
            "74981cb16411480388948a80882bb0d9",
            "cc949081bbdf4a47843480c16eb99492",
            "6dfee6148cb3467eabe0788a37bc745f",
            "0b0467bd2c474dc1bf03842fc2e79021",
            "bc505490d253454ea3578d6199618d5b"
          ]
        },
        "id": "CJDVCMOoZUEU",
        "outputId": "6c7f8d42-b05f-4224-a3ba-4aec70687971"
      },
      "source": [
        "learn = cnn_learner(data, models.resnet50, metrics=error_rate, callback_fns=ShowGraph).to_fp16()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e668eb463b2a4906a6a3517d6737f16c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfn_rGTdZV8C",
        "outputId": "11b29dd7-d9e0-49a7-8d08-3e592d906756"
      },
      "source": [
        "learn.summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method model_summary of Learner(data=ImageDataBunch;\n",
              "\n",
              "Train: LabelList (176020 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "0,1,0,0,0\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (44005 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: CategoryList\n",
              "0,0,1,0,0\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (57458 items)\n",
              "x: ImageList\n",
              "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ., model=Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): AdaptiveConcatPool2d(\n",
              "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
              "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
              "    )\n",
              "    (1): Flatten()\n",
              "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function error_rate at 0x7fa2ddea4ef0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
              "learn: ...\n",
              "loss_scale: 65536\n",
              "max_noskip: 1000\n",
              "dynamic: True\n",
              "clip: None\n",
              "flat_master: False\n",
              "max_scale: 16777216\n",
              "loss_fp32: True], layer_groups=[Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (10): ReLU(inplace=True)\n",
              "  (11): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (13): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (17): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (19): ReLU(inplace=True)\n",
              "  (20): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (24): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (26): ReLU(inplace=True)\n",
              "  (27): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (31): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (33): ReLU(inplace=True)\n",
              "  (34): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (36): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (38): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (39): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (40): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (42): ReLU(inplace=True)\n",
              "  (43): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (44): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (45): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (46): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (47): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (49): ReLU(inplace=True)\n",
              "  (50): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (51): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (52): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (53): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (54): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (56): ReLU(inplace=True)\n",
              "), Sequential(\n",
              "  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (4): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "  (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (9): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (13): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (15): ReLU(inplace=True)\n",
              "  (16): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (20): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (21): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (22): ReLU(inplace=True)\n",
              "  (23): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (27): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (28): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (29): ReLU(inplace=True)\n",
              "  (30): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (33): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (34): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (35): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (36): ReLU(inplace=True)\n",
              "  (37): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (39): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (40): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (41): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (42): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (43): ReLU(inplace=True)\n",
              "  (44): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (48): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (49): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (50): ReLU(inplace=True)\n",
              "  (51): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "  (52): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (53): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (55): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (56): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (57): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (58): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (59): ReLU(inplace=True)\n",
              "  (60): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (62): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (64): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (65): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (66): ReLU(inplace=True)\n",
              "), Sequential(\n",
              "  (0): AdaptiveAvgPool2d(output_size=1)\n",
              "  (1): AdaptiveMaxPool2d(output_size=1)\n",
              "  (2): Flatten()\n",
              "  (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (4): Dropout(p=0.25, inplace=False)\n",
              "  (5): Linear(in_features=4096, out_features=512, bias=True)\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (8): Dropout(p=0.5, inplace=False)\n",
              "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
              ")], add_time=True, silent=False)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWJQLwBRGCzw"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDQSFsHfTlwy"
      },
      "source": [
        "### TODO: \n",
        " * Fit generator on input sample \n",
        " * Apply learned params to test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di4J9q4tFvDX"
      },
      "source": [
        "new_base_dir = 'dataset_folder'\n",
        "training_sub_path = 'train'\n",
        "test_sub_path = 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E4g2E6d-zaA"
      },
      "source": [
        "IMG_SIZE = (96, 96)\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k4QVBZuaU8V",
        "outputId": "e03ce2eb-7f98-4109-9a92-c2ab57c50c37"
      },
      "source": [
        "imagenet_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GB0eddZfz8o"
      },
      "source": [
        "def custom_norm(x, mean=None, std=None):\n",
        "  if mean is None:\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "  if std is None:\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "  mean, std = np.array(mean), np.array(std)\n",
        "  image = np.array(x)\n",
        "  \n",
        "  return (image - mean[None, None, ...]) / std[None, None, ...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYZHe2aRGRbE"
      },
      "source": [
        "data_generator = ImageDataGenerator(rotation_range=90, \n",
        "                                    width_shift_range=[0.2, -0.2], \n",
        "                                    height_shift_range=[0.2, -0.2], \n",
        "                                    brightness_range=[0.3, 1], \n",
        "                                    zoom_range=[0.5, 1], \n",
        "                                    horizontal_flip=True, \n",
        "                                    vertical_flip=True, \n",
        "                                    channel_shift_range=150.0, \n",
        "                                    fill_mode='wrap', \n",
        "                                    validation_split=0.2,\n",
        "                                    rescale=1./255,\n",
        "                                    preprocessing_function=custom_norm)\n",
        "#,                                    featurewise_std_normalization=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd0F8Xg2GZzZ",
        "outputId": "b4bfda7b-2a53-4acc-b028-e9f2fd1755dd"
      },
      "source": [
        "train_data_iterator = data_generator.flow_from_directory('{}/{}'.format(new_base_dir, 'train'), \n",
        "                                                         target_size=(96, 96),\n",
        "                                                         class_mode='binary', \n",
        "                                                         subset='training', \n",
        "                                                         batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 176021 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgiD0KIaGbDa",
        "outputId": "075ce93b-d31a-4435-85a2-f1f403e22608"
      },
      "source": [
        "validation_data_iterator = data_generator.flow_from_directory('{}/{}'.format(new_base_dir, 'train'), \n",
        "                                                              target_size=(96, 96),\n",
        "                                                              class_mode='binary', \n",
        "                                                              subset='validation', \n",
        "                                                              batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 44004 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kVhq_ASGcQF"
      },
      "source": [
        "STEP_SIZE_TRAIN = train_data_iterator.n//train_data_iterator.batch_size\n",
        "STEP_SIZE_VALIDATION = validation_data_iterator.n//validation_data_iterator.batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGoxNMKuGfM0"
      },
      "source": [
        "# Load Backbone model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjAdj6FtGelF"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diuf5LCrGp2i"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_data_iterator))\n",
        "#feature_batch = base_model(image_batch)\n",
        "#print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAZihPnvpc4Q"
      },
      "source": [
        "image_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkzIt_HaGwtZ",
        "outputId": "a0025b9a-6596-42e7-d99c-e06cf860689c"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 102, 102, 3)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 48, 48, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 48, 48, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 48, 48, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 50, 50, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 24, 24, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 24, 24, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 24, 24, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 24, 24, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 24, 24, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 24, 24, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 24, 24, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 24, 24, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 24, 24, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 24, 24, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 24, 24, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 24, 24, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 24, 24, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 24, 24, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 24, 24, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 24, 24, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 24, 24, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 24, 24, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 24, 24, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 24, 24, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 24, 24, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 24, 24, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 24, 24, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 12, 12, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 12, 12, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 12, 12, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 12, 12, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 12, 12, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 12, 12, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 12, 12, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 12, 12, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 12, 12, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 12, 12, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 12, 12, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 12, 12, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 12, 12, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 6, 6, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 6, 6, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 6, 6, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 6, 6, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 6, 6, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 6, 6, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 6, 6, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 6, 6, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 6, 6, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 6, 6, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 6, 6, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 6, 6, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 6, 6, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 6, 6, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 6, 6, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 6, 6, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 6, 6, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 6, 6, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 6, 6, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 6, 6, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 6, 6, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 6, 6, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 6, 6, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 6, 6, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 6, 6, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 6, 6, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 3, 3, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 3, 3, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 3, 3, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 3, 3, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 3, 3, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 3, 3, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 3, 3, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 3, 3, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 3, 3, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 3, 3, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 3, 3, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 3, 3, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9NGYaiOM4OF"
      },
      "source": [
        "# Add Top Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueFuZ7XtOlGh"
      },
      "source": [
        "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "x = base_model(inputs, training=False)\n",
        "avgpool = tf.keras.layers.AveragePooling2D((3,3), padding=\"same\")(x)\n",
        "maxpool = tf.keras.layers.MaxPooling2D((3,3), padding=\"same\")(x)\n",
        "x = tf.keras.layers.Concatenate()([avgpool, maxpool])\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(2)(x)\n",
        "model = tf.keras.Model(inputs, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Ekdh2L8YRa",
        "outputId": "0a190a72-3dd3-4f5d-9d64-15baad90c5c3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "resnet50 (Functional)           (None, 3, 3, 2048)   23587712    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           resnet50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 1, 1, 2048)   0           resnet50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 1, 4096)   0           average_pooling2d[0][0]          \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4096)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 4096)         16384       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 4096)         0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            1026        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,704,834\n",
            "Trainable params: 25,642,498\n",
            "Non-trainable params: 62,336\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM328swqGTtX"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFOopg6OF-t4"
      },
      "source": [
        "# Find Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDxcubrmL64L"
      },
      "source": [
        "\"\"\"\n",
        "https://github.com/surmenok/keras_lr_finder/blob/master/keras_lr_finder/lr_finder.py\n",
        "\"\"\"\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LRFinder:\n",
        "    \"\"\"\n",
        "    Plots the change of the loss function of a Keras model when the learning rate is exponentially increasing.\n",
        "    See for details:\n",
        "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.losses = []\n",
        "        self.lrs = []\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        # Log the learning rate\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.lrs.append(lr)\n",
        "\n",
        "        # Log the loss\n",
        "        loss = logs['loss']\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        # Check whether the loss got too large or NaN\n",
        "        if batch > 5 and (math.isnan(loss) or loss > self.best_loss * 4):\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if loss < self.best_loss:\n",
        "            self.best_loss = loss\n",
        "\n",
        "        # Increase the learning rate for the next batch\n",
        "        lr *= self.lr_mult\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "\n",
        "    def find(self, x_train, y_train, start_lr, end_lr, batch_size=64, epochs=1, **kw_fit):\n",
        "        # If x_train contains data for multiple inputs, use length of the first input.\n",
        "        # Assumption: the first element in the list is single input; NOT a list of inputs.\n",
        "        N = x_train[0].shape[0] if isinstance(x_train, list) else x_train.shape[0]\n",
        "\n",
        "        # Compute number of batches and LR multiplier\n",
        "        num_batches = epochs * N / batch_size\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(num_batches))\n",
        "        # Save weights into a file\n",
        "        initial_weights = self.model.get_weights()\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.lr, start_lr)\n",
        "\n",
        "        callback = LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs))\n",
        "\n",
        "        self.model.fit(x_train, y_train,\n",
        "                       batch_size=batch_size, epochs=epochs,\n",
        "                       callbacks=[callback],\n",
        "                       **kw_fit)\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.set_weights(initial_weights)\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.lr, original_lr)\n",
        "\n",
        "    def find_generator(self, generator, start_lr, end_lr, epochs=1, steps_per_epoch=None, **kw_fit):\n",
        "        if steps_per_epoch is None:\n",
        "            try:\n",
        "                steps_per_epoch = len(generator)\n",
        "            except (ValueError, NotImplementedError) as e:\n",
        "                raise e('`steps_per_epoch=None` is only valid for a'\n",
        "                        ' generator based on the '\n",
        "                        '`keras.utils.Sequence`'\n",
        "                        ' class. Please specify `steps_per_epoch` '\n",
        "                        'or use the `keras.utils.Sequence` class.')\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(epochs * steps_per_epoch))\n",
        "\n",
        "        # Save weights into a file\n",
        "        initial_weights = self.model.get_weights()\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.lr, start_lr)\n",
        "\n",
        "        callback = LambdaCallback(on_batch_end=lambda batch,\n",
        "                                                      logs: self.on_batch_end(batch, logs))\n",
        "\n",
        "        self.model.fit_generator(generator=generator,\n",
        "                                 epochs=epochs,\n",
        "                                 steps_per_epoch=steps_per_epoch,\n",
        "                                 callbacks=[callback],\n",
        "                                 **kw_fit)\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.set_weights(initial_weights)\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.lr, original_lr)\n",
        "\n",
        "    def plot_loss(self, n_skip_beginning=10, n_skip_end=5, x_scale='log'):\n",
        "        \"\"\"\n",
        "        Plots the loss.\n",
        "        Parameters:\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "        \"\"\"\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], self.losses[n_skip_beginning:-n_skip_end])\n",
        "        plt.xscale(x_scale)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss_change(self, sma=1, n_skip_beginning=10, n_skip_end=5, y_lim=(-0.01, 0.01)):\n",
        "        \"\"\"\n",
        "        Plots rate of change of the loss function.\n",
        "        Parameters:\n",
        "            sma - number of batches for simple moving average to smooth out the curve.\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "            y_lim - limits for the y axis.\n",
        "        \"\"\"\n",
        "        derivatives = self.get_derivatives(sma)[n_skip_beginning:-n_skip_end]\n",
        "        lrs = self.lrs[n_skip_beginning:-n_skip_end]\n",
        "        plt.ylabel(\"rate of loss change\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(lrs, derivatives)\n",
        "        plt.xscale('log')\n",
        "        plt.ylim(y_lim)\n",
        "        plt.show()\n",
        "\n",
        "    def get_derivatives(self, sma):\n",
        "        assert sma >= 1\n",
        "        derivatives = [0] * sma\n",
        "        for i in range(sma, len(self.lrs)):\n",
        "            derivatives.append((self.losses[i] - self.losses[i - sma]) / sma)\n",
        "        return derivatives\n",
        "\n",
        "    def get_best_lr(self, sma, n_skip_beginning=10, n_skip_end=5):\n",
        "        derivatives = self.get_derivatives(sma)\n",
        "        best_der_idx = np.argmin(derivatives[n_skip_beginning:-n_skip_end])\n",
        "        return self.lrs[n_skip_beginning:-n_skip_end][best_der_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs-AlS_gGFJf"
      },
      "source": [
        "lr_finder = LRFinder(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZfD8xsHMgas",
        "outputId": "61062f8a-841c-401e-f15d-652df61748e7"
      },
      "source": [
        "lr_finder.find_generator(train_data_iterator, start_lr=0.00001, end_lr=1, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2751/2751 [==============================] - 923s 329ms/step - loss: 1.6837\n",
            "Epoch 2/2\n",
            "2751/2751 [==============================] - 109s 40ms/step - loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "DdYtA_8RGnbr",
        "outputId": "173f6393-a923-4a39-898c-48a3951f3a91"
      },
      "source": [
        "lr_finder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1nTMkw44rH9",
        "outputId": "152d5c8e-b509-4fba-c998-27026074b2c4"
      },
      "source": [
        "lr_finder.get_best_lr(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003162277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwU8MFfzUGug"
      },
      "source": [
        "# Fit one cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJdASdKDUI3O"
      },
      "source": [
        "\"\"\"\n",
        "https://www.avanwyk.com/tensorflow-2-super-convergence-with-the-1cycle-policy/\n",
        "\"\"\"\n",
        "\n",
        "class CosineAnnealer:\n",
        "    def __init__(self, start, end, steps):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.steps = steps\n",
        "        self.n = 0\n",
        "        \n",
        "    def step(self):\n",
        "        self.n += 1\n",
        "        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n",
        "        return self.end + (self.start - self.end) / 2. * cos\n",
        "\n",
        "\n",
        "class OneCycleScheduler(Callback):\n",
        "    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n",
        "        super(OneCycleScheduler, self).__init__()\n",
        "        lr_min = lr_max / div_factor\n",
        "        final_lr = lr_max / (div_factor * 1e4)\n",
        "        phase_1_steps = steps * phase_1_pct\n",
        "        phase_2_steps = steps - phase_1_steps\n",
        "        \n",
        "        self.phase_1_steps = phase_1_steps\n",
        "        self.phase_2_steps = phase_2_steps\n",
        "        self.phase = 0\n",
        "        self.step = 0\n",
        "        \n",
        "        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n",
        "                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n",
        "        \n",
        "        self.lrs = []\n",
        "        self.moms = []\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.phase = 0\n",
        "        self.step = 0\n",
        "\n",
        "        self.set_lr(self.lr_schedule().start)\n",
        "        self.set_momentum(self.mom_schedule().start)\n",
        "        \n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        self.lrs.append(self.get_lr())\n",
        "        self.moms.append(self.get_momentum())\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        self.step += 1\n",
        "        if self.step >= self.phase_1_steps:\n",
        "            self.phase = 1\n",
        "            \n",
        "        self.set_lr(self.lr_schedule().step())\n",
        "        self.set_momentum(self.mom_schedule().step())\n",
        "        \n",
        "    def get_lr(self):\n",
        "        try:\n",
        "            return tf.keras.backend.get_value(self.model.optimizer.lr)\n",
        "        except AttributeError:\n",
        "            return None\n",
        "        \n",
        "    def get_momentum(self):\n",
        "        try:\n",
        "            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n",
        "        except AttributeError:\n",
        "            return None\n",
        "        \n",
        "    def set_lr(self, lr):\n",
        "        try:\n",
        "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        except AttributeError:\n",
        "            pass # ignore\n",
        "        \n",
        "    def set_momentum(self, mom):\n",
        "        try:\n",
        "            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n",
        "        except AttributeError:\n",
        "            pass # ignore\n",
        "\n",
        "    def lr_schedule(self):\n",
        "        return self.phases[self.phase][0]\n",
        "    \n",
        "    def mom_schedule(self):\n",
        "        return self.phases[self.phase][1]\n",
        "    \n",
        "    def plot(self):\n",
        "        ax = plt.subplot(1, 2, 1)\n",
        "        ax.plot(self.lrs)\n",
        "        ax.set_title('Learning Rate')\n",
        "        ax = plt.subplot(1, 2, 2)\n",
        "        ax.plot(self.moms)\n",
        "        ax.set_title('Momentum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smE5yk059U61"
      },
      "source": [
        "epochs = 3\n",
        "#lr = lr_finder.get_best_lr(1)\n",
        "lr = 0.003162277\n",
        "steps = STEP_SIZE_TRAIN * epochs\n",
        "lr_schedule = OneCycleScheduler(lr, steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "vavJ4Zex9fY2",
        "outputId": "e0805843-7fcd-4cc8-b810-89055b864df1"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.MSE, metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data_iterator, validation_data=validation_data_iterator, epochs=epochs, callbacks=[lr_schedule], verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0df47c218d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m             steps=data_handler.inferred_steps)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, callbacks, add_history, add_progbar, model, **params)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'OneCycleScheduler' object has no attribute 'set_model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfYE7PPRTYhv"
      },
      "source": [
        "# References\n",
        "\n",
        "  * https://github.com/priya-dwivedi/Deep-Learning/blob/master/resnet_keras/Residual_Networks_yourself.ipynb"
      ]
    }
  ]
}